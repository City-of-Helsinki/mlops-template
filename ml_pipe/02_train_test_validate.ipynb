{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# | default_exp train_test_val\n",
    "%load_ext lab_black\n",
    "# nb_black if running in jupyter\n",
    "%load_ext autoreload\n",
    "# automatically reload (local) python modules if they are updated\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, test, validate & save to model store\n",
    "\n",
    "> Train and evaluate your model on real data. If it passes tests, save to to model store.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***input:*** clean and tidy dataset from data notebook + ML model class from model notebook\n",
    "\n",
    "***output:*** evaluated, trained and (optionally) model store saved ML model\n",
    "\n",
    "***description:***\n",
    "\n",
    "Edit this and the other text cells to describe your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from your_module.model import your_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imports from repository root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to import /app local modules to this notebook:\n",
    "current = os.path.abspath(\"\")\n",
    "parent_directory = os.path.dirname(current)\n",
    "sys.path.append(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_store import ModelStore, PickleModelStore, MlFlowModelStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag this cell as 'parameters' to utilise papermills notebook parameterization!\n",
    "seed = 0\n",
    "\n",
    "# acceptance test criterion\n",
    "loss_margin = 0.05\n",
    "loss_min_allowed = 0.85\n",
    "loss_max_allowed = 0.999\n",
    "# a hypothetical ethical test statistic\n",
    "max_bias_allowed = 0.15\n",
    "\n",
    "# model store type\n",
    "model_store_impl = \"pickle\"\n",
    "# if pickle:\n",
    "model_pickle_path = \"../local_data/bundle_latest.pickle\"\n",
    "# if mlflow:\n",
    "mlflow_tracking_uri = \"file:../local_data/mlruns\"\n",
    "mlflow_registry_uri = \"sqlite:///../local_data/mlflow.sqlite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make direct derivations from the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load clean and tidy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Depending on the file format and your variables, you might have to redefine datatypes in your dataframe!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training, testing and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0.89\n",
    "test_loss = 0.87\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also include statistical tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = 0.86\n",
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate numerically for ethical issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_factor = 0.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceptance testing\n",
    "\n",
    "Is the model 'good enough' for production?\n",
    "Define criterion and tests for 'good enough'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example, rewrite according to your project\n",
    "all_tests_passed = (\n",
    "    # test for underfitting\n",
    "    np.all(np.array([train_loss, test_loss, val_loss]) > loss_min_allowed)\n",
    "    # test for overfitting\n",
    "    and np.all(np.array([train_loss, test_loss, val_loss]) < loss_max_allowed)\n",
    "    # test for leakage and overfitting\n",
    "    and np.all(\n",
    "        np.abs([train_loss - test_loss, train_loss - val_loss, test_loss - val_loss])\n",
    "        < loss_margin\n",
    "    )\n",
    "    # test for ethical issues,\n",
    "    # use as many metrics & tests as needed for this!\n",
    "    and bias_factor < max_bias_allowed\n",
    ")\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update trained model and results to model store\n",
    "\n",
    "If tests are passed, publish trained model and results to model store.\n",
    "\n",
    "Check out `examples/_model_store*` notebooks on how to do this with your choice of model store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_tests_passed:\n",
    "    # your code here\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of this notebook\n",
    "\n",
    "Trained and evaluated model, saved to a model store."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
